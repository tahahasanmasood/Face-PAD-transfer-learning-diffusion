{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment: pt_fpad  \n",
    "Python: 3.10.4     \n",
    "Pytorch: 2.1.1+cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_real = 0\n",
    "class_label_attack = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Attack Dataset:  \n",
    "Training -> 360 (Real 60, Attack Fixed 150, Attack Hand 150) ->  360/1200 * 100 = 30%  \n",
    "Validation -> 360 (Real 60, Attack Fixed 150, Attack Hand 150) -> 360/1200 * 100 = 30%  \n",
    "Testing -> 480 (Real 80, Attack Fixed 200, Attack Hand 200) -> 480/1200 * 100 = 40%  \n",
    "Total = 1200  \n",
    "\n",
    "Replay Mobile Dataset:\n",
    "\n",
    "Training -> 312 (Real 120, Attack 192) ->  312/1030 * 100 = 30.29%  \n",
    "Validation -> 416 (Real 160, Attack 256) -> 416/1030 * 100 = 40.38%  \n",
    "Testing -> 302 (Real 110, Attack 192) -> 302/1030 * 100 = 29.32%  \n",
    "Total = 1030  \n",
    "\n",
    "Rose-Youtu Dataset:  \n",
    "Training -> 1397 (Real 358, Attack 1039) -> 1397/3495 * 100 = 40%  \n",
    "Validation -> 350 (Real 90, Attack 260) -> 350/3495 * 100 = 10%  \n",
    "Testing -> 1748 (Real 449, Attack 1299) -> 1748/3495 * 100 = 50%   \n",
    "Total = 3495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Attack\n",
    "# data_path_test_real = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/real'\n",
    "# data_path_test_attack_fixed = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/attack/fixed'\n",
    "# data_path_test_attack_hand = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/attack/hand'\n",
    "\n",
    "# Replay Mobile\n",
    "# data_path_test_real = '/home/taha/FASdatasets/Sohail/Replay-Mobile/test/real'\n",
    "# data_path_test_attack = '/home/taha/FASdatasets/Sohail/Replay-Mobile/test/attack'\n",
    "\n",
    "# Rose Youtu\n",
    "# data_path_test_real = '/home/taha/FASdatasets/Sohail/Rose_Youtu/test/real'\n",
    "# data_path_test_attack = '/home/taha/FASdatasets/Sohail/Rose_Youtu/test/attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(path, class_label, transform): #Select N frames returned from read_all_frames and assign labels to all samples of same class\n",
    "        frames = read_all_frames(path)\n",
    "        total_frames = list(range(0, frames.shape[0], 1))\n",
    "        selected_samples = 5\n",
    "        selected_frame = total_frames[selected_samples]\n",
    "        samples =[]\n",
    "        # Assign the same class label to all samples\n",
    "        label = class_label\n",
    "        samples =(transform(frames[selected_frame].squeeze()), label)     \n",
    "        return samples\n",
    "\n",
    "def read_all_frames(video_path): # reads all frames from a particular video and converts them to PyTorch tensors.\n",
    "    frame_list = []\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = video.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA) #framesize kept 40, 30 as mentioned in paper but 224, 224 is also fine \n",
    "            frame_list.append(frame)\n",
    "    frame_list = np.array(frame_list)\n",
    "    return frame_list\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_path, class_label):\n",
    "        self.data_path = data_path #path for directory containing video files\n",
    "        self.video_files = [file for file in os.listdir(data_path) if file.endswith('.mov') or file.endswith('.mp4')] #list of video files in the specified directory #.mov for RA and RM, .mp4 for RY\n",
    "        self.class_label = class_label #manually assign class_label for your desired class while loading\n",
    "        self.data_length = len(self.video_files) \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self): # returns the total number of samples in the dataset\n",
    "        return self.data_length\n",
    "\n",
    "    def __getitem__(self, idx): # loads and returns a sample from the dataset at the given index\n",
    "        file = self.video_files[idx]\n",
    "        path = os.path.join(self.data_path, file)\n",
    "        frames= load_samples(path, self.class_label, self.transform)\n",
    "\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Attack Dataset\n",
    "# test_dataset_real = VideoDataset(data_path_test_real, class_label_real)\n",
    "# test_dataset_attack_fixed = VideoDataset(data_path_test_attack_fixed, class_label_attack)\n",
    "# test_dataset_attack_hand = VideoDataset(data_path_test_attack_hand, class_label_attack)\n",
    "\n",
    "# Replay Mobile & Rose Youtu Dataset\n",
    "\n",
    "# test_dataset_real = VideoDataset(data_path_test_real, class_label_real)\n",
    "# test_dataset_attack = VideoDataset(data_path_test_attack, class_label_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Attack Datasets\n",
    "# test_loader_real = DataLoader(test_dataset_real, batch_size=1, shuffle=False)\n",
    "# test_loader_attack_fixed = DataLoader(test_dataset_attack_fixed, batch_size=1, shuffle=False)\n",
    "# test_loader_attack_hand = DataLoader(test_dataset_attack_hand, batch_size=1, shuffle=False)\n",
    "\n",
    "# Replay Mobile & Rose Youtu Dataset\n",
    "# test_loader_real = DataLoader(test_dataset_real, batch_size=1, shuffle=False)\n",
    "# test_loader_attack = DataLoader(test_dataset_attack, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Attack Dataset\n",
    "# concatenated_test_dataset = ConcatDataset([test_dataset_real, test_dataset_attack_fixed, test_dataset_attack_hand])\n",
    "# concatenated_test_loader = DataLoader(concatenated_test_dataset, batch_size=64, shuffle=False, pin_memory=True, num_workers=8)\n",
    "\n",
    "# Replay Mobile & Rose Youtu Dataset\n",
    "# concatenated_test_dataset = ConcatDataset([test_dataset_real, test_dataset_attack])\n",
    "# concatenated_test_loader = DataLoader(concatenated_test_dataset, batch_size=64, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Test set size: {len(concatenated_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=2) #default in_features =1280, out_features = 1000\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the path to your saved model file\n",
    "model_path = '/home/taha/Taha26/pt_fpad/cross_ds_merge/model2/RA_RYR_best_model.pth'\n",
    "\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Load the model's state dictionary\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    test_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "    test_predicted_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "\n",
    "    for test_images, test_labels in concatenated_test_loader:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        test_model_op = model(test_images)\n",
    "        _, test_predicted = torch.max(test_model_op, 1)\n",
    "        test_correct += (test_predicted == test_labels).sum().item() \n",
    "        test_total += test_labels.size(0)\n",
    "\n",
    "        test_cat_labels = torch.cat((test_cat_labels, test_labels))\n",
    "        test_predicted_cat_labels = torch.cat((test_predicted_cat_labels, test_predicted))\n",
    "\n",
    "    test_accuracy = test_correct / test_total * 100  \n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_labels_cpu = test_cat_labels.cpu()\n",
    "test_predicted_cat_labels_cpu = test_predicted_cat_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_cat_labels_cpu, test_predicted_cat_labels_cpu).ravel()\n",
    "\n",
    "print(f'TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}')\n",
    "\n",
    "acc_score = accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "prec_score = precision_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "recall = recall_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "Y_I_val =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
    "sensitivity_val = tp / (tp + fn)\n",
    "specificity_val = tn / (tn + fp)\n",
    "f1score_val = 2 * tp / (2 * tp + fp + fn)\n",
    "FAR = fp/(fp + tn)\n",
    "FRR = fn/(fn + tp)\n",
    "HTER_val = (FAR + FRR)/2\n",
    "EER = (fp+fn)/(tn+fp+fn+tp)\n",
    "val_bacc = balanced_accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "\n",
    "print('Testing Results')\n",
    "print(30*'-')\n",
    "print('Acc:', acc_score, '\\nSen:', sensitivity_val, '\\nSpec:', specificity_val, '\\nYI:', Y_I_val, '\\nF1:', f1score_val, '\\nPrec:', prec_score, '\\nRecall:', recall, '\\nHTER:', HTER_val, '\\nEER:', EER, '\\nBACC:', val_bacc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
