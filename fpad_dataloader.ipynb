{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment: pt_fpad  \n",
    "Python: 3.10.4     \n",
    "Pytorch: 2.1.1+cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_real = 0\n",
    "class_label_attack = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replay Mobile Dataset:\n",
    "\n",
    "Training -> 312 (Real 120, Attack 192) ->  312/1030 * 100 = 30.29%  \n",
    "Validation -> 416 (Real 160, Attack 256) -> 416/1030 * 100 = 40.38%  \n",
    "Testing -> 302 (Real 110, Attack 192) -> 302/1030 * 100 = 29.32%  \n",
    "Total = 1030  \n",
    "\n",
    "Replay Attack Dataset:  \n",
    "Training -> 360 (Real 60, Attack Fixed 150, Attack Hand 150) ->  360/1200 * 100 = 30%  \n",
    "Validation -> 360 (Real 60, Attack Fixed 150, Attack Hand 150) -> 360/1200 * 100 = 30%  \n",
    "Testing -> 480 (Real 80, Attack Fixed 200, Attack Hand 200) -> 480/1200 * 100 = 40%  \n",
    "Total = 1200  \n",
    "\n",
    "Rose-Youtu Dataset:  \n",
    "Training -> 1397 (Real 358, Attack 1039) -> 1397/3495 * 100 = 40%  \n",
    "Validation -> 350 (Real 90, Attack 260) -> 350/3495 * 100 = 10%  \n",
    "Testing -> 1748 (Real 449, Attack 1299) -> 1748/3495 * 100 = 50%   \n",
    "Total = 3495\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Provide dataset path for Replay Mobile and Rose Youtu Datasets e.g \n",
    "# data_path_train_real = '/home/taha/FASdatasets/Sohail/Rose_Youtu/train/real'\n",
    "# data_path_train_attack = '/home/taha/FASdatasets/Sohail/Rose_Youtu/train/attack'\n",
    "\n",
    "# For Replay Attack Dataset e.g.\n",
    "# data_path_train_real = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/real'\n",
    "# data_path_train_attack_fixed = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/attack/fixed'\n",
    "# data_path_train_attack_hand = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/attack/hand'\n",
    "\n",
    "# Follow the same above steps for Validation and Test Datasets\n",
    "\n",
    "data_path_train_real = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/real'\n",
    "# data_path_train_attack = '/home/taha/FASdatasets/Sohail/Rose_Youtu/train/attack'\n",
    "data_path_train_attack_fixed = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/attack/fixed'\n",
    "data_path_train_attack_hand = '/home/taha/FASdatasets/Sohail/Replay_Attack/train/attack/hand'\n",
    "\n",
    "data_path_devel_real = '/home/taha/FASdatasets/Sohail/Replay_Attack/devel/real'\n",
    "# data_path_devel_attack = '/home/taha/FASdatasets/Sohail/Rose_Youtu/devel/attack'\n",
    "data_path_devel_attack_fixed = '/home/taha/FASdatasets/Sohail/Replay_Attack/devel/attack/fixed'\n",
    "data_path_devel_attack_hand = '/home/taha/FASdatasets/Sohail/Replay_Attack/devel/attack/hand'\n",
    "\n",
    "data_path_test_real = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/real'\n",
    "# data_path_test_attack = '/home/taha/FASdatasets/Sohail/Rose_Youtu/test/attack'\n",
    "data_path_test_attack_fixed = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/attack/fixed'\n",
    "data_path_test_attack_hand = '/home/taha/FASdatasets/Sohail/Replay_Attack/test/attack/hand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(path, class_label, transform): #Select N frames returned from read_all_frames and assign labels to all samples of same class\n",
    "        frames = read_all_frames(path)\n",
    "        total_frames = list(range(0, frames.shape[0], 1))\n",
    "        selected_samples = random.sample(total_frames, 1)\n",
    "        samples =[]\n",
    "        # Assign the same class label to all samples\n",
    "        label = class_label\n",
    "        samples =(transform(frames[selected_samples].squeeze()), label)     \n",
    "        return samples\n",
    "\n",
    "def read_all_frames(video_path): # reads all frames from a particular video and converts them to PyTorch tensors.\n",
    "    frame_list = []\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = video.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA) #framesize kept 224,224\n",
    "            frame_list.append(frame)\n",
    "    frame_list = np.array(frame_list)\n",
    "    return frame_list\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_path, class_label):\n",
    "        self.data_path = data_path #path for directory containing video files\n",
    "        self.video_files = [file for file in os.listdir(data_path) if file.endswith('.mov') or file.endswith('.mp4')] #list of video files in the specified directory #.mov for RA and RM, .mp4 for RY\n",
    "        self.class_label = class_label #manually assign class_label for your desired class while loading\n",
    "        self.data_length = len(self.video_files) \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self): # returns the total number of samples in the dataset\n",
    "        return self.data_length\n",
    "\n",
    "    def __getitem__(self, idx): # loads and returns a sample from the dataset at the given index\n",
    "        file = self.video_files[idx]\n",
    "        path = os.path.join(self.data_path, file)\n",
    "        frames= load_samples(path, self.class_label, self.transform)\n",
    "\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for Replay Attack, Replay Mobile and Rose Youtu Datasets\n",
    "\n",
    "train_dataset_real = VideoDataset(data_path_train_real, class_label_real)\n",
    "# train_dataset_attack = VideoDataset(data_path_train_attack, class_label_attack)\n",
    "\n",
    "# For Replay Attack Dataset\n",
    "train_dataset_attack_fixed = VideoDataset(data_path_train_attack_fixed, class_label_attack)\n",
    "train_dataset_attack_hand = VideoDataset(data_path_train_attack_hand, class_label_attack)\n",
    "# Same steps follow for Validation and Test Datasets\n",
    "\n",
    "val_dataset_real = VideoDataset(data_path_devel_real, class_label_real)\n",
    "# val_dataset_attack = VideoDataset(data_path_devel_attack, class_label_attack)\n",
    "val_dataset_attack_fixed = VideoDataset(data_path_devel_attack_fixed, class_label_attack)\n",
    "val_dataset_attack_hand = VideoDataset(data_path_devel_attack_hand, class_label_attack)\n",
    "\n",
    "test_dataset_real = VideoDataset(data_path_test_real, class_label_real)\n",
    "# test_dataset_attack = VideoDataset(data_path_test_attack, class_label_attack)\n",
    "test_dataset_attack_fixed = VideoDataset(data_path_test_attack_fixed, class_label_attack)\n",
    "test_dataset_attack_hand = VideoDataset(data_path_test_attack_hand, class_label_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for Replay Mobile and Rose Youtu Datasets\n",
    "\n",
    "train_loader_real = DataLoader(train_dataset_real, batch_size=1, shuffle=True)\n",
    "# train_loader_attack = DataLoader(train_dataset_attack, batch_size=1, shuffle=True)\n",
    "\n",
    "# For Replay Attack Dataset\n",
    "train_loader_attack_fixed = DataLoader(train_dataset_attack_fixed, batch_size=1, shuffle=True)\n",
    "train_loader_attack_hand = DataLoader(train_dataset_attack_hand, batch_size=1, shuffle=True)\n",
    "# Same steps follow for Validation and Test DataLoader\n",
    "\n",
    "val_loader_real = DataLoader(val_dataset_real, batch_size=1, shuffle=False)\n",
    "# val_loader_attack = DataLoader(val_dataset_attack, batch_size=1, shuffle=False)\n",
    "val_loader_attack_fixed = DataLoader(val_dataset_attack_fixed, batch_size=1, shuffle=False)\n",
    "val_loader_attack_hand = DataLoader(val_dataset_attack_hand, batch_size=1, shuffle=False)\n",
    "\n",
    "test_loader_real = DataLoader(test_dataset_real, batch_size=1, shuffle=False)\n",
    "# test_loader_attack = DataLoader(test_dataset_attack, batch_size=1, shuffle=False)\n",
    "test_loader_attack_fixed = DataLoader(test_dataset_attack_fixed, batch_size=1, shuffle=False)\n",
    "test_loader_attack_hand = DataLoader(test_dataset_attack_hand, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate datasets for Replay Mobile and Rose Youtu Datasets\n",
    "# concatenated_train_dataset = ConcatDataset([train_dataset_real, train_dataset_attack])\n",
    "# concatenated_val_dataset = ConcatDataset([val_dataset_real, val_dataset_attack])\n",
    "# concatenated_test_dataset = ConcatDataset([test_dataset_real, test_dataset_attack])\n",
    "\n",
    "# Concatenate datasets for Replay Attack Dataset\n",
    "concatenated_train_dataset = ConcatDataset([train_dataset_real, train_dataset_attack_fixed, train_dataset_attack_hand])\n",
    "concatenated_val_dataset = ConcatDataset([val_dataset_real, val_dataset_attack_fixed, val_dataset_attack_hand])\n",
    "concatenated_test_dataset = ConcatDataset([test_dataset_real, test_dataset_attack_fixed, test_dataset_attack_hand])\n",
    "\n",
    "concatenated_train_loader = DataLoader(concatenated_train_dataset, batch_size=64, shuffle=True, pin_memory=False, num_workers=8)\n",
    "concatenated_val_loader = DataLoader(concatenated_val_dataset, batch_size=64, shuffle=False, pin_memory=False, num_workers=8)\n",
    "concatenated_test_loader = DataLoader(concatenated_test_dataset, batch_size=64, shuffle=False, pin_memory=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 360\n",
      "Validation set size: 360\n",
      "Test set size: 480\n"
     ]
    }
   ],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Training set size: {len(concatenated_train_dataset)}\")\n",
    "print(f\"Validation set size: {len(concatenated_val_dataset)}\")\n",
    "print(f\"Test set size: {len(concatenated_test_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
